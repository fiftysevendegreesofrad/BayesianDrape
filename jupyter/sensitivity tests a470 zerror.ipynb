{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c31e55de",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name '_centered' from 'scipy.signal.signaltools' (C:\\Users\\Crispin\\Anaconda2\\envs\\bayesiandrape\\lib\\site-packages\\scipy\\signal\\signaltools.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-5828eaf4afa4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msys\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0memcee\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpylab\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstats\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnorm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\bayesiandrape\\lib\\site-packages\\statsmodels\\api.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m                                    \u001b[0mZeroInflatedGeneralizedPoisson\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m                                    ZeroInflatedNegativeBinomialP)\n\u001b[1;32m---> 27\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mtsa\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mapi\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtsa\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mduration\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msurvfunc\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSurvfuncRight\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mduration\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhazard_regression\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPHReg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\bayesiandrape\\lib\\site-packages\\statsmodels\\tsa\\api.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mvector_ar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvecm\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mVECM\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mvector_ar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msvar_model\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSVAR\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mfilters\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mapi\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfilters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtsatools\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mtsatools\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0madd_trend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdetrend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlagmat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlagmat2ds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madd_lag\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\bayesiandrape\\lib\\site-packages\\statsmodels\\tsa\\filters\\api.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mhp_filter\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mhpfilter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mcf_filter\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcffilter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mfiltertools\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmiso_lfilter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvolution_filter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecursive_filter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda2\\envs\\bayesiandrape\\lib\\site-packages\\statsmodels\\tsa\\filters\\filtertools.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfftpack\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfft\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msignal\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignal\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignaltools\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_centered\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtrim_centered\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtools\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalidation\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0marray_like\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mPandasWrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name '_centered' from 'scipy.signal.signaltools' (C:\\Users\\Crispin\\Anaconda2\\envs\\bayesiandrape\\lib\\site-packages\\scipy\\signal\\signaltools.py)"
     ]
    }
   ],
   "source": [
    "import geopandas as gp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import linregress\n",
    "import subprocess\n",
    "import os,sys\n",
    "import emcee\n",
    "import statsmodels.api as sm\n",
    "import pylab\n",
    "from scipy.stats import norm\n",
    "import seaborn as sn\n",
    "import corner\n",
    "from scipy import optimize,linalg\n",
    "import matplotlib.pyplot as plt\n",
    "import multiprocessing \n",
    "\n",
    "def shell(cmd):\n",
    "    #print(cmd)\n",
    "    process = subprocess.Popen([sys.executable]+cmd.split(\" \"),\n",
    "                     stdout=subprocess.PIPE, \n",
    "                     stderr=subprocess.PIPE,text=True)\n",
    "    stdout, stderr = process.communicate()\n",
    "    if not process.returncode==0:\n",
    "        try:\n",
    "            print(cmd)\n",
    "            print(stdout)\n",
    "            print(stderr)\n",
    "        except:\n",
    "            print(\"failed to decode stdout/stderr\")\n",
    "        return False\n",
    "    #print(stdout)\n",
    "    return True\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9416e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "torch.from_numpy(np.array([]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c8df45",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_nets = {\"a470\":\"../data/a470_test_prep.shp\"\n",
    "              }\n",
    "def test_drape(input_net,z_error_prior_scale,slope_prior_scale,slope_continuity_prior_scale,pitch_angle_prior_scale,refresh=True):\n",
    "    input_net_filename = input_nets[input_net]\n",
    "    bayes_output_filename = \"../scratch/\"+os.path.basename(input_net_filename)\\\n",
    "                            + f\"-bdrapez-{z_error_prior_scale}-{slope_prior_scale}-{slope_continuity_prior_scale}-{pitch_angle_prior_scale}.shp\"\n",
    "    if refresh or not os.path.exists(bayes_output_filename):\n",
    "        res=shell(f\"../BayesianDrape.py --TERRAIN-INPUT=../data/wider_terrain_50/all.tif --POLYLINE-INPUT={input_net_filename} \"\n",
    "              f\"--OUTPUT={bayes_output_filename} --Z-ERROR-PRIOR-SCALE={spatial_mismatch_prior_scale} \"\n",
    "              f\"--SLOPE-CONTINUITY-PRIOR-SCALE={slope_continuity_prior_scale} --SLOPE-PRIOR-SCALE={slope_prior_scale} \"\n",
    "              f\"--PITCH-ANGLE-PRIOR-SCALE={pitch_angle_prior_scale} \"\n",
    "              f\"--MAXITER=20000 --DECOUPLE-FIELD=bridge --IGNORE-PROJ-MISMATCH --SPATIAL-MISMATCH-MAX=200\")\n",
    "        if not res:\n",
    "            return False\n",
    "    return bayes_output_filename\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496aa3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def markov_speed_factor(slope):\n",
    "    '''https://link.springer.com/article/10.1007/s11116-019-10021-x#Tab5'''\n",
    "    return (slope>0)*np.exp(-9.044*slope)+(slope<=0)*1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9a07a0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from itertools import tee\n",
    "def pairwise(iterable):\n",
    "    \"s -> (s0,s1), (s1,s2), (s2, s3), ...\"\n",
    "    a, b = tee(iterable)\n",
    "    next(b, None)\n",
    "    return zip(a, b)\n",
    "\n",
    "def elev_change(geom):\n",
    "    ec = 0\n",
    "    for (_,_,z1),(_,_,z2) in pairwise(list(geom.coords)):\n",
    "        ec += abs(z2-z1)\n",
    "    return ec\n",
    "\n",
    "def plot_elev_profile(geom,title):\n",
    "    plt.figure()\n",
    "    zs = [geom.coords[0][2]]\n",
    "    xs = [0]\n",
    "    for (x1,y1,z1),(x2,y2,z2) in  pairwise(list(geom.coords)):\n",
    "        xs += [xs[-1] + ((y2-y1)**2+(x2-x1)**2)**0.5]\n",
    "        zs += [z2]\n",
    "    plt.scatter(xs,zs)\n",
    "    plt.plot(xs,zs)\n",
    "    plt.xlabel(\"Horizontal distance (metres)\")\n",
    "    plt.ylabel(\"Elevation (metres)\")\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "def cycletime(slope,length):\n",
    "    # bodge based on linear model for now:\n",
    "    # 0% slope = factor of 1\n",
    "    # 5% slope = factor of 2.2 \n",
    "    # slopefac = slope*100/5*1.2+1\n",
    "    slopefac = 1./markov_speed_factor(slope)\n",
    "    return slopefac*length\n",
    "\n",
    "# this is equiv to ct = ec*100/5*1.2 + len when previously we were comparing on ec\n",
    "# i.e. comparing on 24*ec+len which will lessen importance of ec on long links\n",
    "# is this the desired result? i wanted to study outliers more; i guess this studies outliers of grade?\n",
    "\n",
    "def get_resids_r_ll(df,x,y):\n",
    "    lr = linregress(df[x],df[y])\n",
    "    resids = df[y]-(lr.intercept+lr.slope*df[x])\n",
    "    scale = resids.std()\n",
    "    loglik = norm(loc=0,scale=scale).logpdf(resids).sum()\n",
    "    return resids,lr.rvalue,loglik,lr.slope,lr.intercept\n",
    "        \n",
    "   \n",
    "def evaluate_drape_raw(smps,sps=90,scps=90,paps=np.inf,compare=\"ELEVCHANGE\",maxct=8000,maxec=300,label=\"\"):\n",
    "    #slope = np.arctan(sloperat*smp)*180/np.pi did i have this before to remove interactions?\n",
    "    draped_net_filename = test_drape(\"a470\",smps,sps,scps,paps)\n",
    "    if not draped_net_filename:\n",
    "        return -np.inf\n",
    "\n",
    "    draped_net = gp.read_file(draped_net_filename)\n",
    "    draped_net[\"draped_elev_change\"]=[elev_change(geom) for geom in draped_net.geometry]\n",
    "    draped_net[\"length\"]=draped_net.geometry.length\n",
    "\n",
    "    def height(s):\n",
    "        return float(s)\n",
    "    draped_net[\"os_elev_change\"] = draped_net.apply(lambda row: height(row[\"inDirectio\"])+height(row[\"inOpposite\"]),\n",
    "                                                    axis=1)\n",
    "\n",
    "    draped_net[\"os_slope\"] = draped_net.os_elev_change/draped_net.length\n",
    "    draped_net[\"draped_slope\"] = draped_net.draped_elev_change/draped_net.length\n",
    "    draped_net[\"os_cycletime\"] = cycletime(draped_net.os_slope,draped_net.length)\n",
    "    draped_net[\"draped_cycletime\"] = cycletime(draped_net.draped_slope,draped_net.length)\n",
    "\n",
    "    \n",
    "    resids,r,ll,slope,intercept = get_resids_r_ll(draped_net,\"draped_elev_change\",\"os_elev_change\")\n",
    "    elev_error_per_len = abs(resids).sum()/draped_net.length.sum()\n",
    "    #print (\"Max elevation outliers\",min(resids),max(resids))\n",
    "    draped_net[\"Eresid\"] = resids\n",
    "    #resids,r,ll,_ = get_resids_r_ll(draped_net,\"os_cycletime\",\"draped_cycletime\")\n",
    "    #print (\"Mean abs ct error per km\",abs(resids).mean()/draped_net.length.sum()*1000)\n",
    "    #print (\"Max ct outliers\",min(resids),max(resids))\n",
    "    #draped_net[\"CTresid\"] = resids\n",
    "    #draped_net.to_file(draped_net_filename)\n",
    "\n",
    "    #print(\"max ct\",max(draped_net.os_cycletime.max(),draped_net.draped_cycletime.max()))\n",
    "    #maxec_actual = max(draped_net.os_elev_change.max(),draped_net.draped_elev_change.max())\n",
    "    #assert maxec_actual<maxec\n",
    "\n",
    "    #draped_net.plot.scatter(\"os_elev_change\",\"draped_elev_change\",xlim=(0,maxec),ylim=(0,maxec))\n",
    "    #draped_net.plot.scatter(\"os_cycletime\",\"draped_cycletime\",xlim=(0,maxct),ylim=(0,maxct))\n",
    "\n",
    "    # ID=1172 in highways_finaltest_prep\n",
    "    a470 = draped_net[draped_net.ID==-428].geometry.iloc[0]\n",
    "    plot_elev_profile(a470,\"Problem elevation profile 3 (a470)\")\n",
    "    \n",
    "       \n",
    "    outputs = [\n",
    "        (\"label\",label),\n",
    "        (\"smp\",smps),\n",
    "        (\"slope\",sps),\n",
    "        (\"cont\",scps),\n",
    "        (\"ang\",paps),\n",
    "        (\"R\",r),\n",
    "        (\"loglik\",ll),\n",
    "        (\"coeff\",slope),\n",
    "        (\"int\",intercept),\n",
    "        (\"ec/len err\",elev_error_per_len),\n",
    "        (\"min outlier\",min(resids)),\n",
    "        (\"max outlier\",max(resids)),\n",
    "        (\"a470 ec\",elev_change(a470)),\n",
    "    ]\n",
    "    for name,value in outputs:\n",
    "        print(f\"{name}: {value}\")\n",
    "    \n",
    "    keys = [x[0] for x in outputs]\n",
    "    values = [x[1] for x in outputs]\n",
    "    outfile = \"sensitivity4.csv\"\n",
    "    try:\n",
    "        df = pd.read_csv(outfile)\n",
    "    except FileNotFoundError:\n",
    "        df = pd.DataFrame(columns=keys)\n",
    "    df = df.append(dict(zip(keys,values)),ignore_index=True)\n",
    "    df.to_csv(outfile,index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f557c7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "zeps = np.linspace(0,5,10)\n",
    "\n",
    "def sensitivity(slope=90,cont=np.inf,pitch=np.inf,label=\"sens\"):\n",
    "    for smp in smps:\n",
    "        evaluate_drape_raw(smp,slope,cont,pitch,label=label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224a6425",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#sensitivity(slope=2.66,pitch=1.28,label=\"slp+pitch2\")\n",
    "#sensitivity(slope=2.66,cont=2.66,pitch=1.28*2,label=\"slp+cont+weakpitch2\")\n",
    "sensitivity(slope=2.66,label=\"slope2\")\n",
    "sensitivity(cont=2.66,label=\"cont2\")\n",
    "#sensitivity(pitch=1.28,label=\"pitch2\")\n",
    "sensitivity(slope=2.66,cont=2.66,label=\"slp+cont2\")\n",
    "#sensitivity(slope=2.66,cont=2.66,pitch=1.28,label=\"all2\")\n",
    "#sensitivity(slope=2.66,pitch=1.28*2,label=\"slp+weakpitch2\")\n",
    "#sensitivity(slope=2.66,cont=2.66/2,label=\"slp+weakcont\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66fb5d78",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "models = [(\"slope2\",\"Slope\"),\n",
    "          (\"slp+weakcont\",\"Slope + weak continuity\"),\n",
    "         (\"cont2\",\"Slope continuity\"),\n",
    "         (\"pitch2\",\"Pitch angles\"),\n",
    "         (\"slp+cont2\",\"Slope + slope continuity\"),\n",
    "         (\"slp+pitch2\",\"Slope + pitch angles\"),\n",
    "         #(\"slp+cont+weakpitch2\",\"Slope + continuity + weak pitch\"),\n",
    "         (\"all2\",\"Slope + continuity + pitch\")]\n",
    "         #(\"slp+weakpitch2\",\"Slope + weak pitch\") ]\n",
    "\n",
    "def senstest(column,ylabel,title,legend=True):\n",
    "    plt.figure()\n",
    "    df = pd.read_csv(\"sensitivity4.csv\")\n",
    "    for key,label in models:\n",
    "        model = df[df.label==key]\n",
    "        plt.plot(model.smp,model[column],label=label)\n",
    "        model = model[model.smp>3]\n",
    "        maxrow = model[model[column]==model[column].max()]\n",
    "        minrow = model[model[column]==model[column].min()]\n",
    "        print(f\"Max {column} for {key}: {float(maxrow[column]):.3f} for smp={float(maxrow.smp)}\")\n",
    "        print(f\"Min {column} for {key}: {float(minrow[column]):.3f} for smp={float(minrow.smp)}\")\n",
    "    plt.xlabel(\"Spatial Mismatch Prior Scale (metres)\")\n",
    "    plt.ylabel(ylabel)\n",
    "    if legend:\n",
    "        plt.legend()\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "senstest(\"loglik\",\"Log Likelihood\",\"Fit with OS data\")\n",
    "senstest(\"R\",\"R\",\"Correlation with OS data\")\n",
    "senstest(\"coeff\",\"Regression Coefficient\",\"Bias\")\n",
    "senstest(\"int\",\"metres\",\"Regression intercept\")\n",
    "senstest(\"ec/len err\",\"ratio\",\"Total elevation error per unit length\")\n",
    "senstest(\"min outlier\",\"metres\",\"Min outlier (overpredicted elevation change)\")\n",
    "senstest(\"max outlier\",\"metres\",\"Max outlier (underpredicted elevation change)\")\n",
    "senstest(\"a470 ec\",\"metres\",\"Elevation change on a470 link\")\n",
    "#senstest(\"ncn ec\",\"metres\",\"Elevation change on NCN link\",True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
